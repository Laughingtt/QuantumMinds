# QuantumMinds

代码仓库：[[GitHub]](https://github.com/Laughingtt/QuantumMinds)

模型仓库： [[OpenXLab]](https://openxlab.org.cn/models/detail/DD-learning/InternLM-LaoWuMao)

演示视频：[[BiliBili]](https://www.bilibili.com/video/BV1ey421v7ED/?vd_source=16767f3f20bb565fbab7d8c5b43737ef)

在线体验Demo：[[OpenXLab]](https://demo.shdgft.com/)

![yingying.png](images%2Fyingying.png)

# 1. 背景

随着社会的发展、竞争关系的加剧、现代人的工作和生活节奏越来越快，大家的心理压力都急剧增加，心理健康问题也日益突出。特别是这几年在新冠疫情的影响下，据丁香医生《2022国民健康洞察报告》，91%的人自认为有心理问题，这些问题具有多样性和普遍性，主要表现在以下几个方向：

1. 压力问题：生活和工作节奏加快，工作、经济和人际关系等方面压力成为主要的心理负担。长期处于高压状态可能导致身心疲惫，甚至引发各种疾病。
2. 焦虑和抑郁：对未知的恐惧、对失败的担忧以及对未来的焦虑是现代人常见的心理问题。长期的担忧和焦虑会让人内耗，从而导致过度思虑导致失眠、抑郁等问题。抑郁症现已成为一种常见的心理疾病，其不仅影响个体的心理问题，还可能对家庭和社会造成负担。
3. 外界刺激：现代化给人们带来了便利也带来了更多接触负面能量的渠道，攀比、嫉妒、自卑等情绪的放大和持续刺激也会导致心理健康问题。

调整生活方式、保持充足的睡眠、均衡的饮食和适度的运动有助于提高身体和心理的健康水平，培养兴趣爱好、保持正向的社交活动也有助于缓解压力。当我们感到无法自行应对心理问题时，寻求专业心理咨询或治疗是明智的选择。但精神分析师、心理咨询师是供不应求的，且大部分人应该还怀有传统的不愿意见心理医生的思想。

可喜的是，在国家的重视和指导下：党的二十大报告中强调了“重视心理健康和精神卫生”；“十四五”国民健康规划将心理健康内容明确纳入发展目标；“十四五”优质高效医疗卫生服务体系建设实施方案提出加快完善省、市、县各级心理健康和精神卫生防治体系，大家对心理健康的关注度不断提高。心理健康已经成为抖音、B站等平台用户最关注的内容之一，热度持续不减，讨论话题也日益增多。然而，心理问题因人而已，大众化的视频和帖子并不能帮助一个人精准且全面的了解自己的心理问题，亦无法提供个性化的心理辅导和建议。

“唠五毛”正是在这样现状下的产物。“唠五毛”，网络用语，并非指金钱交易，而是带有希望有人陪伴、与人聊天的愿望。我们不希望名字过于正式是希望这款产品自带轻松、愉快的感觉，意在让用户在轻松的氛围中分享自己的想法和情绪。这款陪伴型的智能问答机器人，希望为现代人打造一片心灵的栖息地。在这里，用户可以畅所欲言，分享生活的点点滴滴，不必担心隐私泄露，不必担心旁人的眼光，感受来自受过专业精神分析训练和心理学研究机器人的关怀与陪伴，有针对性的回答用户的疑问和顾虑，7/24为用户提供情绪价值和解决方案。

智能问答机器人名为“小萤火”，小名“萤萤”。我们设计它为一个充满温暖与希望的形象。一个微小但坚定的光点，在夜色中闪烁，周围环绕着柔和的光环，这个光点既是萤萤本身，也代表着她的光芒。萤萤设计的色彩上，我们使用温暖的黄色和金色调，以及深蓝和黑色的背景，以突出光明与黑暗的对比。这个设计中，萤萤的形象是一个抽象的拟人化的萤火虫，用她的身体散发出温暖的光芒。她的形态是简洁而优雅的，带有一些自然元素，比如小翅膀，体现她的自由和轻盈。萤萤的脸带着微笑，眼神温柔而坚定，仿佛在告诉每一个看到她的人，无论前路如何漆黑，总有一束光在等待着他们。这个logo不仅代表着萤萤这个角色，也象征着希望、指引和温暖。它传达的信息是：即使在最黑暗的时刻，也有微小的光芒能够带来改变，指引方向。

# 2. 技术与创新

## 查询流程

![vecdb_flow.png](images%2Fvecdb_flow.png)

## 检索

![retrieval.png](images%2Fretrieval.png)

## 2.1.产品现状

随着大语言模型在各种领域中的广泛应用，其在心理健康领域的应用也正在逐渐展现出巨大的潜力。在精神健康咨询应用中的探索，很多产品已初露头角：1）心灵健康大模型灵心（SoulChat）是一款基于ChatGLM-6B
并进行全量参数指令微调的大语言模型，主要通过构建单轮长文本心理咨询指令与答案和多轮回答数据共同进行模型微调，意在提升模型的共情能力、引导用户倾诉的能力并提供合理的建议。2）职业教练（Career
Coach）是一款应对职场上的心理焦虑，意在帮助用户在职场上获得提升的产品。该产品基于 InternLM2-chat-7B 大模型，通过 Xtuner
对自有数据集和公开数据集 smile
微调出一个用于职场的心理大模型。以上两个模型更多倾向于问答交互和引导，从多轮的产品演示来看，灵心大模型更多是以简短的回答和提问的形式去引导用户倾诉；职业教练更多倾向于缓解用户在职场环境中体验到的紧张和焦虑。心理疾病初步诊断和情绪价值提供相结合的机器人目前还没有。

## 2.2.创新和优势

“唠五毛”是基于 InternLM2-chat-7B 并通过 Xtuner 指令微调+外挂知识库+KGQA
问答系统的带有温度的心理疾病初步诊断大模型。它会对用户的问题进行专业分析和理解：首先会判断输入的问题是否和心理疾病相关，若相关，唠五毛会输出疾病可能的种类并给出建议；若非心理疾病相关问题或判断病情不严重，唠五毛会往舒缓用户情绪的方向引导，提供真诚的指导和建议。不同于已有的心理健康大模型，

我们在技术上的创新点主要表现在以下三个方面：

1. 整合并集成了基于知识图谱的 KGQA
   系统。知识图谱的图搜索可以补充文档搜索的短板，检索出更丰富的信息（例如检索与某个症状相挂钩的所有心理疾病）。另一方面，基于专家经验构建的知识图谱在准确率上非常可靠，可以大大减少大模型的幻觉问题，很好的相互补充。

2. smile 数据库，构建更高质量的语料库，然后对模型进行类似 self-instruct 方式的心理健康垂类领域的指令微调；

3. 基于 langchain 对微调后的模型增加外挂知识库（RAG），提升模型的决策和问题解决能力，为用户提供深度的知识支持，增加模型的知识丰富度并减少幻觉；

### 2.2.1. 指令微调

#### 2.2.1.1. 数据集

Smile 数据集(论文链接地址：https://arxiv.org/pdf/2305.00450.pdf )包含了 35.2 万条心理健康的对话数据，该数据集通过 ChatGPT
改写真实的心理互助 QA
为多轮的心理健康支持多轮对话，其对话主题、词汇和篇章语义丰富多样，符合长程多轮对话的应用场景，为开发面向心理健康咨询相关的专用大语言模型提供了较高质量的语料基础。通过对数据集的研究和理解，我们发现该数据集存在一些可以继续优化的地方，例如：

1. 352,143 条语料中，有 292 条（约 0.1%）为重复数据，去重后为 351,851 条；

2. 有一些数据中有明显非相关信息，比如这一条语料，需要对回答做相应数据清理：

    1. 问题：求助者：我明白了，我觉得我的问题确实没有那么严重,
       只是需要调整自己的心态，放松一下。支持者：你说得没错，改变心态也是非常重要的一步。当我们放松下来，接受自己的真实感受，认真审视自己的价值观，就可以让我们得到更多的能量、更多的快乐，而且也能让我们变得更加自信，更加强大。一切都会好起来的。求助者：谢谢你的鼓励，我觉得心情已经好多了。支持者：

    2. 回答：不用谢，很高兴能够帮到你，如果你还需要帮助，随时找我。也请记住，你并不孤单，有我一直在支持你。(Translation:
       \nHelp-seeker: Recently, I\'ve been feeling verytired, like I\'m being suffocated and I don\'t know what to
       do.\nSupporter: When Ihear you say that, I completely understand your feelings of discomfort and fatigue,and the
       sense of not having the energy to face or deal with things. We all havethese emotions sometimes, and it seems
       like we can\'t control them. However,there are ways we can change our current situation, such as setting aside
       time forourselves to relax and unwind, and relieve stress.\nHelp-seeker: You are right. Ihaven\'t given myself
       enough time to relax. But I always feel like I am toocapricious. I said yes to everything, even things I should
       say "no" to, and now I\'mtoo tired.\nSupporter: Thinking about this, I think we all need to learn to be morefirm
       with our own personal boundaries. Saying "no" is actually a form of protectionand care for ourselves. When we
       learn to refuse some excessive or unnecessarydemands, we can make ourselves become more relaxed, happier and help
       othersunderstand our bottom line. Try to start small, and gradually becomebetter.\nHelp-seeker: You make sense;
       I\'ll try to say "no" and rechargemyself.\nSupporter: Very good. Remember, we don\'t always have to work or
       beperfect for others. Sometimes just doing our best and enjoying life is enough.Instead of trying to please
       others, we should work and live for ourselves. This will not only make us more confident but also increase our
       sense of happiness.\nHelp-seeker: I understand now; my problem isn\'t that serious, I just

       need to adjust my mindset and relax.\nSupporter: Don\'t mention it; I\'m glad I

       could help. If you need help again, feel free to find me. Also, please remember that

       you are not alone; I will always support you.)

    3. 也有一些数据中，回答部分非常短，甚至没有内容，对提问者而言没有任何帮助。比如下面几个

       例子：

       1)回答为空：

       a. 问题：求助者：最近总是经历着情绪波动，有时候会突然感觉非常痛苦，但是自己又

       无法控制（以下文字省略，原问题共 1,470 个字符）

       b.回答：[]

        2)

       回答仅为两个字符明且没有实质帮助：

       a.问题：求助者：我非常感谢您的回应。但是我有些困惑，您刚刚提到让我重新找个心理咨询师。我担心如果我换了治疗师之后，“重建心灵”的过程会更加困难，甚至会

       让我更加沮丧。（以下文字省略，原问题共 1,734 个字符）

       b.回答：非常

       3)回答仅为 3 个字符，且没有实质帮助：

       a.问题：求助者：最近和自恋性父母在一起相处越来越困难了，他们总是把他们认为的我的需求强加给我，而我真正的需求常常被忽略。这让我很痛苦，不知道该怎么办。（以下文字省略，原问题共
       1,780 个字符）

       b.回答：加油！

    4. Smile 的数据包含了不同轮次的对话语料，其中我们最关心的是单轮，也就是第一轮的心理相关的问答语料，所以我们需要做数据的筛选，仅选择首轮对话。这部分的数据为
       54,697 条。
       ![datatable.png](images%2Fdatatable.png)
    5. 对于筛选出来的首轮对话，回答的平均长度为 85 个字符，中位数为 77 个字符。以下是两个典型的例子。对于心理健康相关的咨询问题，这样的回答明显偏短，离大语言模型的
       3H 要求（Harmless,Helpful, Honest。无害、有帮助、诚恳）距离较远，在 “有帮助”和“诚恳”这两个维度上有欠缺。事实上，下面第 2
       个例子中的回答，并不是一个算得上是”harmless”的回答，而这时 LLM 在落地使用环节中最不能被突破的底线。所以我们的感觉是
       smile 这份语料数据的质量并不能算很好。

       1)例子 1：

       a.问题：求助者：最近我遇到了一个问题。大姑姐离婚，不要女儿，于是我收养了她女儿。但是现在我儿子和姑姐女儿的关系很紧张，她自己也不做家务，我该怎么办？支持者：

       b.回答：看来你很烦恼啊。那你先了解一下孩子的意见吧。问问她喜不喜欢在你家，或者她想不想跟她的父亲一起生活。

       2)例子 2：

       a.问题：求助者：最近有点不开心，身边的同学总是会议论人，很多时候他们的话语让我觉得很难过，我都不知道该怎么应对了。支持者：

       b.回答：你真的体会到了他们的无比的苛刻，因为他们总是愚蠢的判断别人。但我想告诉你，这并不代表你有问题，他们的问题更大。

针对 smile 数据中存在的问题，我们从 smile 的原始数据出发，结合知乎上精选出的近百条专业的心理问答帖子，通过以下步骤制作出了一份高质量的心理健康相关的问答语料库：

1. 对 smile 的数据进行筛选首轮对话数据、去重、清洗不相关文本等数据预处理。
2. 从中筛选出 11,275 重点问题。这些问题的回答普遍偏短，远远达不到 3H（Helpful, Harmless, and
   Honest）的要求。故我们将之与知乎专业心理问答帖子相结合，利用百度 ERNIE 3.5 大语言模型的
   API，对以上重点问题通过 few shot in-context learning 的方式进行了 Prompt Engineering，从
   而得到了比 smile 原始语料中质量高的多的回答。实现了高质量指令微调数据集的开发。
3. 以下是一个例子：

1) 问题：求助者：最近我总是经常感到压抑，好像什么事情都提不起劲来做。我很困惑，不
   知道该怎么办。支持者：
2) Smile 数据中的回答：听起来你正处于一个不太好的情绪状态。可以先尝试找找导致你这
   种情况的原因，想一想有哪些事情让你感到压抑和消极？
3) 我们自建语料库中的回答：首先，理解你的感受非常重要。每个人都会有情绪低落的时候，
   感到压抑和失去动力是很常见的情绪体验。面对这种情况，可以尝试以下几种方法来缓解
   和应对：
   a. 自我反思与了解：花点时间自我反思，了解自己为什么会感到压抑。是不是最近遇到
   了什么困难或压力？是不是有什么事情让你感到不安或担忧？通过了解自己的情绪
   来源，可以更好地应对。
   b. 寻求支持：与亲朋好友分享你的感受。他们可以给你提供情感支持，帮助你分担压力。
   如果情况严重或持续时间较长，也可以考虑寻求专业心理咨询师的帮助。
   c. 保持健康的生活方式：保持良好的睡眠、饮食和运动习惯有助于缓解压力和提升心情。
   尽量保持规律的作息时间，避免熬夜。饮食要均衡，多吃蔬菜水果。适当进行运动，
   如散步、跑步、瑜伽等，有助于释放压力。
   d. 寻找兴趣爱好：尝试做一些自己喜欢的事情，如听音乐、看电影、读书、画画等。这
   些活动可以帮助你分散注意力，缓解压力，提升心情。
   e. 放松技巧：学习一些放松技巧，如深呼吸、冥想、渐进性肌肉松弛等。这些技巧可以
   帮助你缓解紧张情绪，放松身心。
   f. 设定小目标：为自己设定一些小目标，逐步完成。这样可以帮助你找回动力和成就感，
   提升自信心。
   g. 保持积极心态：尽量保持积极的心态，相信自己可以克服困难。尝试从正面的角度看
   待问题，寻找解决问题的方法。
   如果以上方法无法缓解你的压抑情绪，或者你的情绪问题持续存在且影响到日常生活，建议及
   时寻求专业心理咨询师的帮助。他们可以提供更具体的建议和支持，帮助你应对情绪问题。记
   住，寻求帮助并不是弱点，而是勇气和智慧的表现。
   最后，希望你能尽快走出困境，恢复积极的心态和生活状态。加油！
   从以上例子不难看出，我们构建的语料库在心理健康咨询方面的质量（以 3H 准则来衡量：无害、有
   帮助、诚恳）比 smile 原始数据的有明显的提升。

#### 2.2.1.2. 微调

唠五毛，以 internlm2-7b-chat 作为基座模型并进行了指令微调。我们通过 xtuner 并基于官方
tutorial 中的 internlm2_chat_7b_qlora_oasst1_e3_copy 微调模板进行了修改。按照格式要求，将新构
建的 1.1 万条高质量问答对进行数据加工，生成满足 system，input 和 output 形式的数据集，喂入模型。
让模型进一步对用户的输入、反馈和情绪波动进行深度分析，从而建立拥有更多心理学方面专业知识和精
神分析经验的大模型，以便更好的理解每个客户的需求和情绪状态。
在训练过程中，我们使用了 8 张 A100-40G，并开启了 qlora 和 deepspeed deepspeed_zero2 对
微调内容进行加速。完成训练后，按照推荐操作，将训练得到的 pth 文件转换为 hf 文件，并将其合并到原
模型代码中。

#### 2.2.2. KGQA 系统

知识图谱问答系统（KGQA），是一种利用知识图谱来回答用户提出的问题的技术。唠五毛最初一轮
的判断是对心理疾病的诊断，对于疾病的诊断需要非常精准和专业的知识，集成 KGQA 系统不仅可以很好
的保证回答的准确性和一致性，也能帮助外挂知识库整合散落在各处的知识点，通过构建心理疾病方面的
知识图谱，KGQA 可以处理多个实体和关系的复杂查询并输出专业的回答。
整体链路如下：

1. 知识图谱先对心理疾病相关的问题给出相关知识（比如：我有一些症状，可能得了什么心理疾病）；
2. 这个知识会和问题一起用于 RAG 的知识检索，相比于只针对用户问题去检索会得到更全面的回答；
3. 这个知识也会直接传给大模型，辅助回答；
4. 大模型会基于自身的知识去补充知识图谱关联的信息，并用于最终的回答。
5. 相较 RAG：可以把分散在各个地方的知识，通过图谱间点关联的方式找到，这无法通过 RAG 召回
   文本的方式解决。
   2.2.2.1. KGQA 的技术实现流程
1. 知识图谱的构建

1) 从心理学相关网站爬取需要的知识并进行清洗，去重，字符串格式处理等工作。
2) 按顺序建立节点，建立节点的属性，建立节点与节点之间的关系。节点与属性如下：
   i. 实体类型：disease，alternate_name，pathogenic_site，department，symptom，
   check，susceptible_crowd
   ii. 关系类型：disease_alternate_name，disease_pathogenic_site，disease_symptom，
   disease_check，disease_department，disease_complication，
   disease_confusable，disease_crowd
   iii. 属性类型：expert_remind，infectivity，heredity

2. 抽取原始数据字典中各字段的数据属性值集合，分别写入 txt 文件，作为问答系统中的特征词库。
3. 程序启动后，会先根据预设的特征词和疑问词对用户提供的问题进行分类，根据不同分类启动对
   应的 Cypher 语句在 neo4j 数据库中查询关联的结果
4. 将结果添加至 input 问题之后，用于：
   a) 后续对 RAG 文档知识库进行相关性检索，除了与问题相关，还会找出与图谱知识相关的文
   档，提升 retrieve 性能
   b) 添加在 prompt 内，一起作为 input 输入给 LLM，提供辅助信息
   2.2.2.2. 实现结果展示
   加入知识图谱问答系统后，询问“听觉障碍可能患上的疾病”时，红框的结论来自于大模型本身，都
   是生理性疾病，绿框的知识来自于知识图谱的关联查询，返回了听觉障碍这一病症可能来自于哪些心理疾
   病，同时蓝框的内容由大模型对于知识图谱的返回结果又补充了自身的知识内容，从而构筑了一个完整的
   回答。
   ![qa_ex.png](images%2Fqa_ex.png)

### 2.2.3. 外挂知识库（RAG）

#### 2.2.3.1. 知识库

外挂知识库是一种在大模型应用中引入外部知识源的方法，用于增强模型的能力，特别是在处理特定
领域的任务时。我们使用了各类心理学名著共 33 本（详见附录），涵盖心理学理论、心理治愈、自我认
知、人生哲理等各个方面的书籍作为外挂知识库，同时我们使用了知乎的高赞问答对，这些问答对都是基
于真实问题进行的解答。

#### 2.2.3.2. RAG

近期广受大家关注的检索增强生成（RAG）是提高大模型回答质量的有效手段，该方法对用户提出的
问题进行向量化，并从向量数据库里召回和用户问题相似的文档片段，弥补模型可能在微调中未涵盖的知
识面，从而增强模型的全面性。
我们基于 langchain 框架实现 RAG。代码原型参照官方 langchain 应用代码并进行了改进，改进点
如下：

1. 向量化模型改为网易 Qanything 的 Bce-embedding-base-v1，该模型是在官方 tutorial 使用的
   sentence-transfomers 模型的基础上进行的优化，该嵌入方法检索能力更强，可以检索到和问题更相关
   的知识并入到回答的内容中;
2. 我们引入了“重排序”的能力，重排序是 RAG 重要的性能提升手段，我们使用了和向量化模型配
   套的 bce-reranker-base_v1，两者配合的性能在日前公开的本地模型里排名前列;
3. 向量化使用了标准的 500token 的切片和 150 size 的 overlap，实测对于书本类文档的检索性能
   良好；
4. 为了更多利用我们微调后大模型的基座能力，没有召回很多块文本，第一遍向量化时检索出 10 个
   最相关的文本，第二遍重排序后保留其中 3 个作为模型问答的辅助提示；同时经过多次尝试后设定
   score_threshold=0.3，这样当问题与知识库无关时不会有任何召回；
5. 向量知识库使用 FAISS-gpu 替换了默认的 ChromaDB，优点是支持使用 GPU 进行向量化运算，
   提升程序性能；
6. 我们对知乎的心理问答对数据在存入 MD 文件时手动进行了分割分块，以保证各个问答的文本之
   间在检索时不会交叉混淆。 3. 结果展示

## 3.1. 心理疾病初步诊断结果展示

### 3.1.1. 问答 round1 - 我最近偶尔听不清别人说话，我是不是病了

![round1.png](images%2Fround1.png)

### 3.1.2. 问答 round2 - 会不会是听觉障碍啊

![round2.png](images%2Fround2.png)

### 3.1.3. 问答 round3 - 会不会是心理问题导致的呢

![round3.png](images%2Fround3.png)

### 3.1.4. 问答 round4 - 我不想见医生

![round4.png](images%2Fround4.png)

## 3.2. 精神分析和情绪价值提供结果展示

现有如下案例问：如何温柔的拒绝舔狗？
![round5.1.png](images%2Fround5.1.png)
![round5.2.png](images%2Fround5.2.png)

# 4. 产品体验

快速开始：https://demo.shdgft.com/

# 5. 附录

外挂知识库共 33 本名著（均为中文译本）详情如下：

1. 《弗洛伊德及其后继者：现代精神分析思想史》- 斯蒂芬 · A.米切尔 / 玛格丽特 · J.布莱克
2. 《积极心理学》- 克里斯托弗 · 彼得森
3. 《动机与人格》- 亚伯拉罕 · 哈罗德 · 马斯洛
4. 《性学三论与爱情心理学》- 西格蒙德·弗洛伊德
5. 《自卑与超越》- 阿尔弗雷德 · 阿德勒
6. 《津巴多普通心理学》- 菲利普 · 津巴多
7. 《情商》- 丹尼尔·戈尔曼
8. 《超越自卑》- 阿尔弗雷德 · 阿德勒
9. 《精神分析导论》- 西格蒙德 · 弗洛伊德
10. 《被讨厌的勇气》- 岸见一郎 / 古贺史健
11. 《成功心理学：发现工作和生活的意义》- 丹尼斯‧韦特利
12. 《自我与本我》- 西格蒙德 · 弗洛伊德
13. 《精神分析案例解析》- 南希 · 麦克威廉斯
14. 《梦的解析》- 西格蒙德·弗洛伊德
15. 《生物心理学》- 约翰·比奈尔
16. 《寻找弗洛伊德：精神分析理论与经典案例》- 李武石
17. 《爱的艺术》- 艾里希-弗洛姆
18. 《社会心理学》- 戴维·迈尔斯
19. 《亲密关系》- 罗兰·米勒
20. 《进化心理学》- 戴维·巴斯
21. 《爱的五种能力》- 赵永久
22. 《另一种选择》- 谢丽尔·桑德伯格亚当•格兰特
23. 《感谢自己的不完美》- 武志红
24. 《蛤蟆先生去看心理医生》- 罗伯特·戴博德
25. 《无可摧毁的纯真》- 阿玛斯
26. 《阿德勒理论导读》- 伊娃·德雷克斯·弗格森
27. 《人类行为心理学》- 麦克康纳尔
28. 《你要如何衡量你的人生》- 克莱顿·克里斯坦森
29. 《沉思录》- 马可·奥勒留
30. 《生命的重建》- 露易丝·海
31. 《遇见未知的自己》- 张德芬
32. 《橘子不是唯一的水果》- 珍妮特·温特森
33. 《沉思录：一位罗马帝王的哲学思考》- 马尔库斯·奥勒利乌斯


# 5. 引用仓库
- [InternLM](https://github.com/InternLM/InternLM) - Official release of InternLM2 7B and 20B base and chat models. 200K context support
- [KGQA-Psychological-Counseling](https://github.com/fumuling/KGQA-Psychological-Counseling) - 基于知识图谱的心理咨询智能问答系统